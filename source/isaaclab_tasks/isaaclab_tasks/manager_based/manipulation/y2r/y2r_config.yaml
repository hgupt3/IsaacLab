# ==============================================================================
# Y2R Trajectory Task Configuration
# ==============================================================================
# All configuration for the Y2R trajectory following task.
# Edit this file to change task behavior. Set reward weights to 0 to disable.
# Format: [min, max] for ranges, [initial, final] for curriculum interpolation.
# ==============================================================================

# ==============================================================================
# SIMULATION
# ==============================================================================
simulation:
  physics_dt: 0.01              # 1/100 seconds (100 Hz physics)
  decimation: 2                 # Control at 60 Hz (physics_dt * decimation)
  num_envs: 20480
  env_spacing: 3.0
  replicate_physics: false

# ==============================================================================
# MODE SELECTION
# ==============================================================================
mode:
  use_point_cloud: false        # true = point cloud tracking, false = pose tracking
  use_eigen_grasp: true         # true = 28D eigen grasp, false = 23D full joints

# ==============================================================================
# OBSERVATIONS
# ==============================================================================
observations:
  num_points: 32                # Points sampled per object surface
  clip_range: [-2.0, 2.0]       # Clip observation values
  
  # History lengths for observation groups
  history:
    policy: 5                   # Action history
    proprio: 5                  # Joint pos/vel, hand tips, contact
    perception: 5               # Object point cloud and pose history
    targets: 1                  # No history (targets already encode future)

# ==============================================================================
# TRAJECTORY TIMING
# ==============================================================================
trajectory:
  duration: 10.0                # Total episode length (seconds)
  target_hz: 6.667              # Target update rate (20/3 Hz = 150ms between targets)
  window_size: 5                # Number of lookahead targets in observation
  
  # Phase durations (seconds) - must sum to duration
  phases:
    pickup: 0.5                 # Stationary at start for grasping
    manipulate: 7.5             # Main movement phase with easing
    release: 2.0                # Stationary at goal for release
  
  easing_power: 2.0             # Quadratic ease curves (higher = sharper transitions)

# ==============================================================================
# WORKSPACE BOUNDS
# ==============================================================================
# Relative to robot base frame (meters)
workspace:
  x: [-0.75, -0.35]
  y: [-0.3, 0.3]
  z: [0.28, 0.7]               # [min, max] - above table surface
  table_surface_z: 0.255        # Height of table surface

# ==============================================================================
# WAYPOINTS
# ==============================================================================
# Intermediate points between start and goal (0-2 randomly sampled)
waypoints:
  count: [0, 2]                 # [min, max] waypoints per trajectory
  
  # Position sampling (null = use workspace bounds, else offset from start)
  position_range:
    x: null                     # null = sample from workspace.x
    y: null                     # null = sample from workspace.y
    z: null                     # null = sample from workspace.z
  
  # Orientation randomization
  vary_orientation: true
  max_rotation: 2.0            # Max rotation in radians (~114 degrees)

# ==============================================================================
# GOAL SAMPLING
# ==============================================================================
# Goal is always on table surface with stable orientation
goal:
  x_range: null                 # null = use workspace.x
  y_range: null                 # null = use workspace.y
  table_margin: 0.0             # Keep goal this far from table edge

# ==============================================================================
# REWARDS
# ==============================================================================
# Set weight to 0 to disable any reward
# Thresholds use [initial, final] format - curriculum interpolates between
rewards:
  action_l2:
    weight: -0.003
    
  action_rate_l2:
    weight: -0.003
    
  fingers_to_object:
    weight: 0.5
    std: 0.4
    
  lookahead_tracking:
    weight: 6.0
    std: 0.06                   # Position/point cloud error std
    decay: 0.2                  # Exponential decay for lookahead weights
    contact_threshold: 1.0      # Must have contact (Newtons) to get reward
    rot_std: 0.6                # Rotation error std (pose mode only) 
    
  trajectory_success:
    weight: 10.0
    # Success thresholds [initial (lenient), final (strict)]
    point_cloud_threshold: [0.06, 0.02]     # meters
    position_threshold: [0.06, 0.02]        # meters (pose mode)
    rotation_threshold: [0.6, 0.2]          # radians (pose mode) ~34° → ~11°
    
  early_termination:
    weight: -1.0
    term_keys: ["abnormal_robot", "trajectory_deviation"]
    
  arm_table_penalty:
    weight: -1.0
    table_z: 0.255
    threshold_mid: 0.06         # Safe height above table for links 3,4,5
    threshold_distal: 0.03      # Safe height above table for links 6,7,palm
    
  # Robot-specific (Kuka Allegro)
  good_finger_contact:
    weight: 0.5
    threshold: 1.0              # Contact force threshold (Newtons)

# ==============================================================================
# TERMINATIONS
# ==============================================================================
# Thresholds use [initial, final] format - curriculum interpolates between
terminations:
  trajectory_deviation:
    # Max allowed deviation before episode terminates
    point_cloud_threshold: [0.18, 0.06]     # meters
    position_threshold: [0.7, 0.4] #[0.25, 0.05]        # meters (pose mode)
    rotation_threshold: [3.5, 2.0] #[2.5, 0.5]          # radians (pose mode) ~143° → ~29°

# ==============================================================================
# CURRICULUM (Adaptive Domain Randomization)
# ==============================================================================
curriculum:
  difficulty:
    initial: 0                  # Starting difficulty
    min: 0
    max: 10
    
  # Tolerances to advance difficulty level
  # null = use current success threshold (adaptive with curriculum)
  advancement_tolerances:
    position: null              # null = use success threshold (meters)
    rotation: null              # null = use success threshold (radians)
    point_cloud: null           # null = use success threshold (meters)
    
  # Observation noise curriculum: [initial, final]
  noise:
    joint_pos: [0.0, 0.1]
    joint_vel: [0.0, 0.2]
    hand_tips: [0.0, 0.01]
    object_point_cloud: [0.0, 0.01]
    object_pose: [0.0, 0.01]
    target_point_clouds: [0.0, 0.01]
    target_poses: [0.0, 0.01]
    
  # Gravity scheduling (m/s²)
  gravity:
    initial: [0.0, 0.0, 0.0]
    final: [0.0, 0.0, -9.81]

# ==============================================================================
# DOMAIN RANDOMIZATION
# ==============================================================================
# All ranges are [min, max]
randomization:
  object:
    scale: [0.75, 1.25]
    mass_scale: [0.2, 2.0]
    static_friction: [0.5, 1.0]
    dynamic_friction: [0.5, 1.0]
    restitution: [0.0, 0.0]
    
  robot:
    static_friction: [0.5, 1.0]
    dynamic_friction: [0.5, 1.0]
    restitution: [0.0, 0.0]
    stiffness_scale: [0.5, 2.0]
    damping_scale: [0.5, 2.0]
    joint_friction_scale: [0.0, 5.0]
    
  reset:
    table_xy: [-0.05, 0.05]     # Table position randomization
    object_x: [-0.25, 0.25]     # Object X relative to init
    object_y: [-0.3, 0.3]       # Object Y relative to init
    object_yaw: [-3.14, 3.14]   # Object yaw rotation
    robot_joints: [-0.5, 0.5]   # Joint position offset
    robot_wrist: [-3.0, 3.0]    # Wrist joint (larger range)
    z_offset: 0.0005            # Safety margin above table

# ==============================================================================
# VISUALIZATION
# ==============================================================================
# Set all to false for maximum performance during training
visualization:
  targets: false                 # Show target point clouds
  current_object: false          # Show current object point cloud
  waypoint_region: false         # Show waypoint sampling box
  goal_region: false             # Show goal sampling region on table
  pose_axes: false               # Show axis arrows for poses
  env_ids: []                   # Which envs to visualize ([] = none, null = all)
  debug_print_rewards: false    # Print reward breakdown every 10 steps

# ==============================================================================
# ROBOT-SPECIFIC SETTINGS (Kuka Allegro)
# ==============================================================================
robot:
  action_scale: 0.1
  arm_joint_count: 7
  hand_joint_count: 16
  eigen_dim: 5                  # PCA dimensions for eigen grasp

# ==============================================================================
# PUSH-T MODE (disabled by default)
# ==============================================================================
# When enabled, uses T-shaped object with direct-to-goal trajectory and replanning
push_t:
  enabled: false
  object_usd: "assets/t-shape/t-shape.usd"  # Path to T-shape USD (relative to y2r folder)
  outline_usd: "assets/t-shape_outline/t-shape_outline.usd"  # Path to outline USD for goal visualization
  object_scale: 1.0             # Scale for both object and outline
  outline_position: [-0.55, 0.0]  # Fixed goal position on table
  rolling_window: 3.0           # Trajectory planning horizon (seconds)
  min_speed: 0.02               # Minimum speed (m/s) to prevent infinite slowdown
  include_in_primitives: true   # Include T-shape in random object selection pool

# ==============================================================================
# PROCEDURAL OBJECTS
# ==============================================================================
# Generate random "grown" objects by hierarchically attaching primitives
# Shapes are cached in asset_dir; regenerate only if regenerate=true or count changed
procedural_objects:
  enabled: true
  percentage: 0.4                 # 40% procedural, 60% built-in primitives
  asset_dir: "assets/procedural"  # Relative to y2r folder, auto-created
  regenerate: false               # Force regenerate even if shapes exist
  
  # Generation parameters
  generation:
    num_shapes: 100               # How many unique shapes to generate
    primitives_per_shape: [2, 5]  # [min, max] primitives per object
    base_size: [0.035, 0.075]       # [min, max] base primitive size (meters)
    size_decay: 0.7               # Each child primitive is this fraction of parent
    primitive_types:              # Weighted selection of primitive types
      ellipsoid: 0.2
      box: 0.3
      capsule: 0.2
      cylinder: 0.3
    seed: null                    # Random seed (null = different each generation)
