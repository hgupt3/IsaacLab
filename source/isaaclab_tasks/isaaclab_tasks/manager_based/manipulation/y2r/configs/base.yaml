# ==============================================================================
# Y2R Trajectory Task Configuration
# ==============================================================================
# All configuration for the Y2R trajectory following task.
# Edit this file to change task behavior. Set reward weights to disable.
# Format: [min, max] for ranges, [initial, final] for curriculum interpolation.
# ==============================================================================

# ==============================================================================
# SIMULATION
# ==============================================================================
simulation:
  physics_dt: 0.01              # Physics timestep (seconds)
  decimation: 2                 # Control decimation (steps per action)
  num_envs: 18432
  env_spacing: 3.0
  replicate_physics: false

# ==============================================================================
# MODE SELECTION
# ==============================================================================
mode:
  use_point_cloud: false        # true = point cloud tracking, false = pose tracking
  use_eigen_grasp: true         # true = eigen grasp, false = full joint control
  use_student_mode: false       # true = adds student_perception and student_targets obs groups (point cloud only)

# ==============================================================================
# OBSERVATIONS
# ==============================================================================
observations:
  num_points: 32                # Points sampled per object surface (privileged)
  student_num_points: 16        # Points for student observations (visible point cloud)
  point_pool_size: 256          # Pool size for surface sampling (must be > num_points)
  point_cloud_filter: null      # Set to filter config in task yaml to exclude regions

  # History lengths for observation groups
  history:
    # Teacher observations
    policy: 5                   # Action history length
    proprio: 5                  # Joint pos/vel, hand tips, contact history
    object_pc: 1                # Object point cloud history
    poses: 5                    # Object + hand pose history (kept linked)
    targets: 1                  # Target history (targets already encode future)
    # Student observations (when use_student_mode: true)
    student_pc: 1               # Visible point cloud from pseudo-camera
    student_targets: 1          # Visible target sequence
    student_camera: 1           # Wrist depth camera history

# ==============================================================================
# TRAJECTORY TIMING
# ==============================================================================
# ==============================================================================
# TRAJECTORY (segment-based system)
# ==============================================================================
trajectory:
  target_hz: 10                 # Target update rate (Hz)
  window_size: 5                # Lookahead targets in observation
  easing_power: 1.5             # Ease curve power for waypoint segments
  path_mode: true               # Track along continuous path segment (vs discrete waypoints)
  timing_aware: true            # Use temporal interpolation for path tracking
  release_ease_power: 1.5       # Ease-in power for retreat
  skip_manipulation_probability: 0.01  # Probability of grasp-only episodes

  # Segment-based trajectory composition
  segments:
    - name: "grasp"
      type: "waypoint"
      pose: null              # Computed from start_poses
      duration: 2.0
      hand_coupling_weights:
        full: 1.0

    - name: "explore"
      type: "random_waypoint"
      count_weights: [0.5, 0.5]  # P(0 waypoints)=50%, P(1 waypoint)=50%
      movement_duration: 3.0     # Per-waypoint duration (seconds)
      pause_duration: 0.25       # Per-waypoint pause (seconds)
      position_range:
        x: null                  # null = use workspace bounds
        y: null
        z: null
      vary_orientation: true
      max_rotation: 1.0          # Max rotation (radians)
      hand_coupling_weights:
        full: 0.5
        position_only: 0.5

    - name: "goal"
      type: "waypoint"
      pose: null              # Computed from goal_poses
      duration: 3.0
      hand_coupling_weights:
        full: 0.5
        position_only: 0.5

    - name: "settle"
      type: "waypoint"
      pose: null              # Computed from goal_poses
      duration: 0.1
      hand_coupling_weights:
        full: 0.5
        position_only: 0.5

    - name: "release"
      type: "waypoint"
      pose: null              # Computed: object stays, hand retreats
      duration: 2.0
      hand_coupling_weights:
        none: 1.0             # Hand fully decoupled

# ==============================================================================
# HAND TRAJECTORY (palm pose guidance)
# ==============================================================================
# Generates palm pose targets alongside object trajectory.
# Palm pose is a guiding signal - policy can deviate when necessary.
hand_trajectory:
  enabled: true                # Enable hand pose trajectory generation
  grasp_rot_completion_fraction: 0.4  # Fraction of grasp phase for rotation completion
  boundary_blend_time_s: 1.5   # Blend duration for position_only -> full (seconds)
  
  # Grasp region sampling (surface normal based)
  # Palm approaches from surface normal direction, Z axis (blue) faces object
  grasp_sampling:
    standoff_range: [0.02, 0.06]  # Palm distance from object surface (meters)
    exclude_bottom_fraction: 0.4  # Exclude bottom portion of object surface (table side)
    exclude_toward_robot: true    # Flip grasps where fingers point toward robot
    toward_robot_threshold: -0.05   # Reject if finger_dir.x > threshold
    exclude_upward: true          # Flip grasps where fingers point upward
    upward_threshold: 0.05        # Reject if finger_dir.z > threshold
    # Pre-grasp approach waypoint (null = disabled, direct start→grasp)
    approach_distance: 0.1       # Distance behind grasp for pre-grasp position (meters)
    align_fraction: 0.7           # Fraction of grasp phase for alignment (ignored if approach_distance is null)
    # Fixed direction grasp (null = random sampling)
    fixed_origin_offset: null     # [x,y,z] offset from object center (null = object center)
    fixed_direction: null         # [x,y,z] look direction from grasp origin to find surface point (null = random)
    fixed_hand_roll: null         # Rotation around approach axis (radians)
  
  # Grasp keypoints (perturbed surface points during manipulation for in-hand manipulation)
  # Keypoints are sampled from nearby feasible surface points, ensuring the hand
  # can achieve the pose at each point in the trajectory.
  keypoints:
    count_weights: [0.5, 0.5]      # P(0 keypoints)=50%, P(1 keypoint)=50%
    max_surface_perturbation: 0.04  # Max distance to search for nearby surface points (meters)
    roll_perturbation: 0.3      # Max roll perturbation around approach axis (radians)
    normal_similarity_threshold: -0.05  # Min dot product of normals (prevents flipping to opposite face)

  # Feasibility constraints for hand poses (checked at each keypoint)
  feasibility:
    min_height: 0.02              # Palm must be above table surface + margin (meters)
  
  # Release phase - sample random position in region (like waypoints)
  release:
    position_range:
      x: null                   # null = use workspace.x bounds
      y: null                   # null = use workspace.y bounds  
      z: [0.6, 0.8]           # Safe height range above table
    min_distance_from_object: 0.4  # Ensure palm doesn't overlap with goal object

# ==============================================================================
# WORKSPACE BOUNDS
# ==============================================================================
# Relative to robot base frame (meters)
workspace:
  x: [-0.75, -0.35]
  y: [-0.25, 0.25]
  z: [0.28, 0.65]               # [min, max] above table surface
  table_surface_z: 0.255        # Table surface height (meters)

# ==============================================================================
# GOAL SAMPLING
# ==============================================================================
# Goal is always on table surface with stable orientation
goal:
  x_range: null                 # null = use workspace.x
  y_range: null                 # null = use workspace.y
  table_margin: 0.0             # Keep goal away from table edge (meters)
  return_to_start: false        # If true, goal = start position (for return tasks)

# ==============================================================================
# REWARDS
# ==============================================================================
# Set weight to disable any reward
# Thresholds use [initial, final] format - curriculum interpolates between
rewards:
  action_l2:
    weight: -0.005
    params:
      finger_scale: 0.1
    
  action_rate_l2:
    weight: -0.005
    params:
      finger_scale: 0.1    
    
  fingers_to_object:
    weight: 1.5
    params:
      phases: [grasp, manipulation]    # Active in grasp and manipulation phases
      use_hand_pose_gate: true        # Optional hand pose gating
      std: 0.4
      error_gate_pos_threshold: 0.10   # Position/point-cloud threshold (meters)
      error_gate_pos_slope: 0.05       # Position gate slope (meters)
      error_gate_rot_threshold: 1.0    # Rotation threshold (radians)
      error_gate_rot_slope: 0.5        # Rotation gate slope (radians)
    
  lookahead_tracking:
    weight: 8.0
    params:
      phases: [grasp, manipulation]      # Active in grasp and manipulation phases
      use_hand_pose_gate: true     # Apply hand pose gate from hand_pose_following
      use_contact_gating: true     # Enable/disable contact gating
      std: 0.03                    # Position/point cloud error std
      rot_std: 0.4                 # Rotation error std (pose mode only)
      decay: 0.1                   # Exponential decay for lookahead weights (ignored in path_mode)
      # Soft contact gating: scales tracking reward but never hard-zeros it.
      contact_threshold: 1.0       # Force threshold for contact detection (N)
      contact_ramp: 1.0            # Ramp range for contact factor (N)
      contact_min_factor: 0.05     # Lower bound so reward doesn't fully collapse
      # Negative penalty zones (activates when error > threshold):
      neg_scale: 0.1               # Max penalty magnitude
      neg_threshold: 0.04          # Position error threshold (meters)
      neg_std: 0.1                 # Position penalty growth rate
      rot_neg_threshold: 0.5       # Rotation error threshold (radians)
      rot_neg_std: 1.0             # Rotation penalty growth rate
    
  trajectory_success:
    weight: 15.0
    params:
      phases: [release]               # Active only in release phase
      use_hand_pose_gate: true        # Apply hand pose gate from hand_pose_following
      use_finger_release_gate: true   # Gate sparse bonus by finger release
      # Sparse binary thresholds [initial (lenient), final (strict)]
      # Both pos AND rot must be within threshold for sparse bonus
      pos_threshold: [0.07, 0.04]     # Position/point cloud threshold (meters)
      rot_threshold: [0.7, 0.4]       # Rotation threshold (radians)
      # Dense shaping (fixed, provides gradient toward goal)
      pos_std: 0.03                   # Exp kernel std for dense shaping (meters)
      rot_std: 0.4                    # Exp kernel std for dense shaping (radians)
      sparse_weight: 0.9              # Sparse vs dense weighting
      contact_gate_threshold: 1.0     # Finger force threshold for gate floor (N)
      contact_gate_ramp: 1.0          # Ramp range for gate recovery (N)
      contact_gate_floor: 0.05        # Minimum gate when fingers touching
    
  early_termination:
    weight: -50.0
    params:
      term_keys: ["trajectory_deviation", "hand_pose_deviation", "abnormal_robot"]
    
  arm_table_penalty:
    weight: -0.5
    params:
      table_z: 0.255
      threshold_mid: 0.1         # Safe height above table for mid links
      threshold_distal: 0.05     # Safe height above table for distal links/palm
    
  # Robot-specific (Kuka Allegro)
  good_finger_contact:
    weight: 1.0
    params:
      phases: [manipulation, release]  # Active in all phases
      use_hand_pose_gate: true         # Apply hand pose gate from hand_pose_following
      invert_in_release: true          # Invert reward in release (reward NO contact)
      threshold: 1.0                   # Contact force threshold (N)
    
  finger_manipulation:
    weight: 5.0
    params:
      phases: [manipulation]    # Active in grasp and manipulation phases
      use_hand_pose_gate: true         # Apply hand pose gate from hand_pose_following
      pos_std: 0.02               # Position change std (meters)
      rot_std: 0.2                # Rotation change std (radians)
    
  distal_joint3_penalty:
    weight: -0.5  
    params:
      phases: [grasp, manipulation, release]  # Active in all phases (no phase restriction)
      std: 1.5                    # Larger = more lenient (radians)
      joint_name_regex: ".*_joint_3"
      only_when_contact: false
      contact_threshold: 1.0     # Contact force threshold (N)
    
  palm_velocity_penalty:
    weight: 0.0
    params:
      angular_std: 0.7            # Angular velocity std (rad/s)
      linear_std: 1.0             # Linear velocity std (m/s)
      linear_scale: 0.1           # Scale for linear term relative to angular
    
  palm_orientation_penalty:
    weight: 0.0
    params:
      std: 1.0                    # Angular deviation std (rad)

  # Penalize being too close to joint soft limits (encourages "comfort zone" postures)
  joint_limits_margin:
    weight: 0.0
    params:
      threshold: 0.95             # Fraction of joint range where penalty starts
      power: 2.0                  # Penalty sharpness near limits

  # Rewards *reducing* current target error (helps recovery if policy freezes).
  tracking_progress:
    weight: 4.0
    params:
      phases: [grasp, manipulation, release]  # Active in all phases
      use_hand_pose_gate: false         # Apply hand pose gate from hand_pose_following
      pos_weight: 1.0
      rot_weight: 1.0
      positive_only: true
      clip: 1.0

  # Hand pose following reward (when hand_trajectory.enabled)
  # Guides hand to follow palm pose trajectory through grasp/manipulation/release
  hand_pose_following:
    weight: 3.5                   # Guiding signal, not strict
    params:
      # Phase-varying tolerances: average of position/rotation kernels
      grasp_pos_tol: 0.03         # Position tolerance during grasp
      grasp_rot_tol: 0.4          # Rotation tolerance during grasp
      manipulation_pos_tol: 0.04  # Position tolerance during manipulation
      manipulation_rot_tol: 0.5   # Rotation tolerance during manipulation
      release_pos_tol: 0.03       # Position tolerance during release
      release_rot_tol: 0.4        # Rotation tolerance during release
      # Per-phase gating - gate other rewards if hand deviates from target
      gate_in_grasp: true         # Gate during grasp phase
      gate_in_manipulation: true  # Gate during manipulation phase
      gate_in_release: true       # Gate during release phase
      gate_pos_threshold: [0.04, 0.06]        # Position: [start dropping, reach minimum]
      gate_rot_threshold: [0.4, 0.6]          # Rotation: [start dropping, reach minimum]
      # Manipulation-specific overrides (null = use default thresholds above)
      manipulation_gate_pos_threshold: [0.04, 0.12]  # Position thresholds for manipulation
      manipulation_gate_rot_threshold: [0.4, 1.2]    # Rotation thresholds for manipulation
  
  # Finger release reward - incentivizes opening hand during release phase
  finger_release:
    weight: 0.0
    params:
      phases: [release]           # Active only in release phase
      scale: 4.0                  # Gradient steepness (higher = stronger push toward open)
  
  # Finger regularizer - penalizes deviation from neutral/default finger pose
  finger_regularizer:
    weight: -0.5                  # Negative = penalty
    params:
      phases: [grasp, release]    # Active in grasp and release phases
      # Default finger joint positions (Allegro hand)
      default_joints: [0.0315, 0.0764, 0.0196, 0.2944, -0.0010, 0.1109, 0.0309, 0.2541, -0.0067, 0.1260, 0.0697, 0.2933, 1.5165, -0.2420, 0.3112, 0.3816]
      std: 1.5                    # Penalty growth with deviation (radians)
  
  # Object stillness - penalizes object movement during grasp/release
  object_stillness:
    weight: -0.5                  # Negative = penalty
    params:
      phases: [release]    # Active in grasp and release phases
      lin_std: 0.02               # Linear velocity std (m/s)
      ang_std: 0.2                # Angular velocity std (rad/s)

# ==============================================================================
# TERMINATIONS
# ==============================================================================
# Thresholds use [initial, final] format - curriculum interpolates between
terminations:
  trajectory_deviation:
    position_threshold: [0.3, 0.1]      # Spatial error (meters)
    rotation_threshold: [3.0, 1.25]       # Rotation error (radians)
  
  hand_pose_deviation:
    position_threshold: [0.3, 0.1]         # Position threshold (meters)
    rotation_threshold: [3.14, 3.14]        # Rotation threshold (radians)

# ==============================================================================
# CURRICULUM (Adaptive Domain Randomization)
# ==============================================================================
curriculum:
  difficulty:
    initial: 0                  # Starting difficulty
    min: 0
    max: 10
    
  # Step-based scheduler (set step_interval to null to disable)
  scheduler: 
    step_interval: 64000        # Floor increases at this interval
    use_performance: true       # Performance can still advance faster than floor
    
  # Tolerances to advance difficulty level
  # null = use current success threshold (adaptive with curriculum)
  advancement_tolerances:
    position: null              # null = use success threshold (meters)
    rotation: null              # null = use success threshold (radians)
    point_cloud: null           # null = use success threshold (meters)
    
  # Observation noise curriculum: [initial, final]
  noise:
    joint_pos: [0.0, 0.1]
    joint_vel: [0.0, 0.1]
    hand_eigen: [0.0, 0.01]
    hand_tips: [0.0, 0.01]
    object_point_cloud: [0.0, 0.01]
    object_pose: [0.0, 0.01]
    hand_pose: [0.0, 0.01]
    target_point_clouds: [0.0, 0.01]
    target_poses: [0.0, 0.01]
    hand_pose_targets: [0.0, 0.01]
    
  gate_floor: [0.4, 0.1] # Hand pose gate floor: [initial, final]
  grasp_scale: [0.4, 0.0] # Grasp phase scaling for lookahead tracking: [initial, final]
    
  # Gravity scheduling (m/s²)
  gravity:
    initial: [0.0, 0.0, -0.0981]
    final: [0.0, 0.0, -9.81]

# ==============================================================================
# DOMAIN RANDOMIZATION
# ==============================================================================
# All ranges are [min, max]
randomization:
  object:
    scale: [0.65, 1.1]
    mass_scale: [0.1, 1.6]
    static_friction: [0.5, 1.0]
    dynamic_friction: [0.5, 1.0]
    restitution: [0.0, 0.0]
    
  robot:
    static_friction: [0.8, 1.2]
    dynamic_friction: [0.8, 1.2]
    restitution: [0.0, 0.0]
    stiffness_scale: [0.8, 1.2]
    damping_scale: [0.8, 1.2]
    joint_friction_scale: [0.8, 1.2]
    
  reset:
    table_xy: [0.0, 0.0]     # Table position randomization
    object_x: [-0.3, 0.3]     # Object X relative to init
    object_y: [-0.35, 0.35]       # Object Y relative to init
    object_yaw: [-3.14, 3.14]   # Object yaw rotation
    robot_joints: [-0.5, 0.5]   # Joint position offset
    robot_wrist: [-1.0, 1.0]    # Wrist joint offset (larger range)
    z_offset: 0.005             # Safety margin above table (meters)
    # Robot base position randomization (world frame, meters)
    robot_base_x: [-0.01, 0.01]    # Front/back
    robot_base_y: [-0.01, 0.01]    # Left/right
    robot_base_z: [0.005, 0.02]      # Up only — robot can't sink into table
    # Camera offset perturbation (camera frame, meters)
    camera_forward: [0.0, 0.002]      # Toward workspace only (not back)
    camera_lateral: [-0.002, 0.002]   # Left/right
    camera_vertical: [-0.002, 0.002]  # Up/down

# ==============================================================================
# VISUALIZATION
# ==============================================================================
# Set all to false for maximum performance during training
visualization:
  targets: false                 # Show target point clouds
  current_object: false          # Show current object point cloud
  student_visible: false         # Show student visible point cloud (blue markers)
  student_target: false          # Show student visible point trajectory (inferno colors)
  waypoint_region: false         # Show waypoint sampling box
  goal_region: false             # Show goal sampling region on table
  pose_axes: false               # Show axis arrows for poses
  hand_pose_targets: false       # Show hand (palm) pose target axes
  grasp_surface_point: false     # Show selected grasp surface point (green sphere)
  env_ids: []                   # Which envs to visualize ([] = none, null = all)
  debug_print_rewards: false    # Print reward breakdown periodically

# ==============================================================================
# ROBOT-SPECIFIC SETTINGS (Kuka Allegro)
# ==============================================================================
robot:
  action_scale: 0.1
  arm_joint_count: 7
  hand_joint_count: 16
  eigen_dim: 5                  # PCA dimensions for eigen grasp
  palm_body_name: "palm_frame"  # Body used for palm pose tracking (Kuka overrides to palm_link)

# ==============================================================================
# PUSH-T MODE (disabled by default)
# ==============================================================================
# When enabled, uses T-shaped object with direct-to-goal trajectory and replanning
push_t:
  enabled: false
  object_usd: "assets/t-shape/t-shape.usd"  # Path to T-shape USD (relative to y2r folder)
  outline_usd: "assets/t-shape_outline/t-shape_outline.usd"  # Path to outline USD for goal visualization
  object_scale: 1.0             # Scale for both object and outline
  outline_position: [-0.55, 0.0]  # Fixed goal position on table
  object_rotation: [0.5, 0.5, -0.5, -0.5]   # Object quaternion wxyz
  outline_rotation: [0.5, 0.5, -0.5, -0.5]  # Outline quaternion wxyz
  goal_offset: null             # [x, y, z] offset from outline position (null = no offset)
  goal_rotation: null           # Goal quaternion wxyz (null = use outline_rotation)
  rolling_window: 3.0           # Trajectory planning horizon (seconds)
  min_speed: 0.02               # Minimum linear speed (m/s) for waypoint replanning
  include_in_primitives: true   # Include T-shape in random object selection pool
  object_z_offset: null         # Center-to-bottom distance (null = auto-compute from mesh)
  outline_z_offset: null        # Center-to-bottom distance (null = auto-compute from mesh)
  outline_has_contacts: false   # Enable collision on outline
  outline_is_kinematic: false   # Make outline fixed/unmovable
  outline_has_gravity: false    # Enable gravity on outline

# ==============================================================================
# PSEUDO CAMERA (for visible point cloud filtering)
# ==============================================================================
# Virtual camera for computing point cloud visibility (self-occlusion)
pseudo_camera:
  position: [-1.0, 0.0, 0.3]     # [x, y, z] relative to env origin (meters)

# ==============================================================================
# WRIST CAMERA  (Gemini 305 depth — pinhole, square pixels, HFOV 88°)
# ==============================================================================
# Wrist-mounted depth camera for student observations
# Intrinsics: fx=fy=662.7px @1280×800 → focal_length=3.19mm, horizontal_aperture=6.17mm
# At 80×50 (native 16:10 aspect): HFOV=88°, VFOV≈62° (within 65°±3° spec)
wrist_camera:
  enabled: false
  width: 80                     # Gemini 305 native 16:10 aspect ratio (1280:800)
  height: 50
  focal_length: 3.19            # 88° HFOV: 6.17 / (2×tan(44°))
  horizontal_aperture: 6.17     # Virtual sensor width (mm)
  clipping_range: [0.04, 1.0]   # Gemini 305 depth range: 4–100 cm

  # Offset: palm_link → camera (opengl convention, Euler degrees)
  # UR5e: computed from URDF transforms inv(T_link6→palm) × T_link6→optical
  offset:
    pos: [-0.1774, -0.021, -0.071]
    rot: [90.0, 90.0, 0.0]

  # Web viewer for remote visualization over SSH
  web_viewer: false
  viewer_port: 8000
  viewer_update_hz: 10

# ==============================================================================
# PROCEDURAL OBJECTS
# ==============================================================================
# Generate random "grown" objects by hierarchically attaching primitives
# Shapes are cached in asset_dir; regenerate only if regenerate=true or count changed
procedural_objects:
  enabled: true
  percentage: 0.6                 # Fraction procedural vs built-in primitives
  asset_dir: "assets/procedural"  # Relative to y2r folder, auto-created
  regenerate: true               # Force regenerate even if shapes exist
  
  # Generation parameters
  generation:
    num_shapes: 1000               # How many unique shapes to generate
    primitives_per_shape: [2, 5]  # [min, max] primitives per object
    base_size: [0.035, 0.06]       # [min, max] base primitive size (meters)
    size_decay: 0.7               # Child size relative to parent
    primitive_types:              # Weighted selection of primitive types
      sphere: 0.1
      box: 0.3
      capsule: 0.2
      cylinder: 0.2
      annulus: 0.2
    seed: null                    # Random seed (null = different each generation)
